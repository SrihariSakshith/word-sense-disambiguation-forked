{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnik Similarity\n",
    "\n",
    "__Anish Sachdeva (DTU/2K16/MC/013)__\n",
    "\n",
    "__Natural Language Processing (Dr. Seba Susan)__\n",
    "\n",
    "In the Resnik Similarity metric we compute the lowest Common subsumer __LCS__ of the given words $w_1$ and $w_2$. We then compute the probability of teh subsumer given a corpus and we then compute the similarity score as $-log{LCS(w_1, w_2)}$. weshow below how to compute the closest possible synsets for 2 given worsdusing the Resnik Similarity and we also then use this metric on our resume to see which document matches most closesly with the 6th document.\n",
    "\n",
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet, wordnet_ic\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('wordnet_ic')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Infinity\n",
    "infinity = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now import the Brown Corpus which is required for computing the probabilities of the Lowest Common Subsumer __LCS__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Brown Corpus\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `closest_synsets` Function \n",
    "This function will compute the 2 closest synsets for any 2 words such that they are most similar as per the Resnik Similarity Metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_synsets(word_1: str, word_2: str):\n",
    "    word_1 = wordnet.synsets(word_1)\n",
    "    word_2 = wordnet.synsets(word_2)\n",
    "    max_similarity = -infinity\n",
    "    try:\n",
    "        synset_1_shortest = word_1[0]\n",
    "        synset_2_shortest = word_2[0]\n",
    "    except:\n",
    "        return None, None, -infinity\n",
    "\n",
    "    for synset_1 in word_1:\n",
    "        for synset_2 in word_2:\n",
    "            if synset_1.pos() != synset_2.pos():\n",
    "                continue\n",
    "            similarity = synset_1.res_similarity(synset_2, ic=brown_ic)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                synset_1_shortest = synset_1\n",
    "                synset_2_shortest = synset_2\n",
    "\n",
    "    return synset_1_shortest, synset_2_shortest, max_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us test our function with a few sample words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java Definition: an island in Indonesia to the south of Borneo; one of the world's most densely populated regions\n",
      "Island Definition: a land mass (smaller than a continent) that is surrounded by water\n",
      "similarity: 6.688645509739946\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'java'\n",
    "word_2 = 'island'\n",
    "word_1_synset, word_2_synset, similarity = closest_synsets(word_1, word_2)\n",
    "\n",
    "print(word_1.capitalize() + ' Definition:', word_1_synset.definition())\n",
    "print(word_2.capitalize() + ' Definition:', word_2_synset.definition())\n",
    "print('similarity:', similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java Definition: a platform-independent object-oriented programming language\n",
      "Language Definition: a systematic means of communicating by the use of sounds or conventional symbols\n",
      "similarity: 5.792086967391197\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'java'\n",
    "word_2 = 'language'\n",
    "word_1_synset, word_2_synset, similarity = closest_synsets(word_1, word_2)\n",
    "\n",
    "print(word_1.capitalize() + ' Definition:', word_1_synset.definition())\n",
    "print(word_2.capitalize() + ' Definition:', word_2_synset.definition())\n",
    "print('similarity:', similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nickel Definition: a United States coin worth one twentieth of a dollar\n",
      "Dime Definition: a United States coin worth one tenth of a dollar\n",
      "similarity: 7.455288045755159\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'nickel'\n",
    "word_2 = 'dime'\n",
    "word_1_synset, word_2_synset, similarity = closest_synsets(word_1, word_2)\n",
    "\n",
    "print(word_1.capitalize() + ' Definition:', word_1_synset.definition())\n",
    "print(word_2.capitalize() + ' Definition:', word_2_synset.definition())\n",
    "print('similarity:', similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nickel Definition: a hard malleable ductile silvery metallic element that is resistant to corrosion; used in alloys; occurs in pentlandite and smaltite and garnierite and millerite\n",
      "Gold Definition: a soft yellow malleable ductile (trivalent and univalent) metallic element; occurs mainly as nuggets in rocks and alluvial deposits; does not react with most chemicals but is attacked by chlorine and aqua regia\n",
      "similarity: 5.442191710437843\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'nickel'\n",
    "word_2 = 'gold'\n",
    "word_1_synset, word_2_synset, similarity = closest_synsets(word_1, word_2)\n",
    "\n",
    "print(word_1.capitalize() + ' Definition:', word_1_synset.definition())\n",
    "print(word_2.capitalize() + ' Definition:', word_2_synset.definition())\n",
    "print('similarity:', similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see from the above examples that our function and the Resnik Similarity Metric are giving good results and we are finding words close to each other based on the context.\n",
    "\n",
    "We will now test this metric on our resume.\n",
    "\n",
    "### Loading The Documents from our Resume\n",
    "Our Resume was divided into 6 documents and each document contains 6 keywords that occurred with the highest frequency in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The documents are:\n",
      "[['python', 'data', 'structures', 'students', 'com', 'delhi'],\n",
      " ['java', 'auckland', 'geometry', 'mathematics', 'theory', 'batch'],\n",
      " ['cern', 'applications', 'worked', 'research', 'group', 'core'],\n",
      " ['worked', 'also', 'requests', 'participated', 'many', 'teaching'],\n",
      " ['structures', 'computer', 'algorithms', 'java', 'university', 'mathematics'],\n",
      " ['trinity', 'college', 'london', 'plectrum', 'guitar', 'grade']]\n"
     ]
    }
   ],
   "source": [
    "documents = pickle.load(open('../assets/documents.p', 'rb'))\n",
    "print('The documents are:')\n",
    "pprint.pprint(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Documents in Tabular Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Documents:\n",
      "            0             1           2             3           4            5\n",
      "0      python          data  structures      students         com        delhi\n",
      "1        java      auckland    geometry   mathematics      theory        batch\n",
      "2        cern  applications      worked      research       group         core\n",
      "3      worked          also    requests  participated        many     teaching\n",
      "4  structures      computer  algorithms          java  university  mathematics\n",
      "5     trinity       college      london      plectrum      guitar        grade\n"
     ]
    }
   ],
   "source": [
    "documents_table = pd.DataFrame(documents)\n",
    "print('\\nDocuments:')\n",
    "print(documents_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Similarity Between 6th & Other Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The similarity coefficients are:\n",
      "\n",
      "    trinity   college    london  plectrum    guitar     grade\n",
      "0  5.738632  2.855294  1.531834  1.531834      -inf  1.290026\n",
      "1  0.596229  1.290026 -0.000000 -0.000000 -0.000000  7.054047\n",
      "2      -inf  0.801759      -inf -0.000000  0.801759  3.335576\n",
      "3      -inf      -inf -0.000000      -inf      -inf  2.644521\n",
      "4  2.855294  2.305849 -0.000000  1.290026  2.305849  2.644521\n"
     ]
    }
   ],
   "source": [
    "similarity_mat = np.zeros((len(documents) - 1, len(documents[0])))\n",
    "\n",
    "for column, keyword in enumerate(documents[len(documents) - 1]):\n",
    "    for row in range(len(documents) - 1):\n",
    "        similarity_mat[row][column] = closest_synsets(keyword, documents[row][column])[2]\n",
    "\n",
    "print('\\nThe similarity coefficients are:\\n')\n",
    "similarity = pd.DataFrame(similarity_mat, columns=documents[5])\n",
    "print(similarity.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving The Similarity Coefficient Matrix in a File\n",
    "We do so, so that we can view reslts later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = open('../assets/resnik_similarity_matrix.txt', 'w')\n",
    "results.write(similarity.to_string())\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting document with Maximum/Minimum Similarity with the 6th Document.\n",
    "We can clearly see that for the first column (word: __trinity__) maximum similarity is 5.738 with __python__ and minimum is \n",
    "$ -\\infty$ with __worked__ and __structures__.\n",
    "\n",
    "For the word __college__, maximum is 2.855 with __data__ and minimum is $- \\infty$ with __computer__. \n",
    "\n",
    "For the word __london__, maximum is 1.531 with __structures__ and minimum is $- \\infty$ with __worked__.\n",
    "\n",
    "For the word __plectrum__, maximum is 1.531 with __students__ and minimum is $- \\infty$ with __participated__.\n",
    "\n",
    "For the word __guitar__, maximum is 2.305 with __university__ and minimum is $- \\infty$ with __com__ and __many__.\n",
    "\n",
    "For the word __grade__, maximum is 7.054 with __batch__ and minimum is 1.290 with __delhi__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above data we can create vectors for maximum and minimum indices for each column\n",
    "max = [0, 0, 0, 0, 4, 1]\n",
    "min = [3, 3, 2, 3, 4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document with Minimum Similarity to 6th document: ['worked', 'also', 'requests', 'participated', 'many', 'teaching']\n",
      "Document with Maximum Similarity to 6th document: ['python', 'data', 'structures', 'students', 'com', 'delhi']\n"
     ]
    }
   ],
   "source": [
    "# document with least/maximum similarity\n",
    "document_min_similarity = stats.mode(min).mode[0]\n",
    "document_max_similarity = stats.mode(max).mode[0]\n",
    "\n",
    "print('\\nDocument with Minimum Similarity to 6th document:', documents[document_min_similarity])\n",
    "print('Document with Maximum Similarity to 6th document:', documents[document_max_similarity])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
